#PBS -N %RUN%%STORMNUM%_analysis_%CYC%
#PBS -j oe
#PBS -S /bin/bash
#PBS -q %QUEUE%
#PBS -A %PROJ%-%PROJENVIR%
#PBS -l walltime=00:30:00
#PBS -l place=vscatter:excl,select=10:ncpus=128:mpiprocs=16:ompthreads=8
#PBS -l debug=true

model=hafs
export cyc="%CYC%"
%include <head.h>
%include <envir-p1.h>

export TOTAL_TASKS='160'
export NCTSK='16'
export OMP_THREADS='8'
export OMP_PLACES=cores
export OMP_STACKSIZE=1G
export FI_OFI_RXM_SAR_LIMIT=3145728

export storm_num="%STORMNUM%"

# versions file for hafs sets $model_ver and $code_ver
#module use ${HOMEhafs}/modulefiles/
#module load hafs.wcoss2
#module use $HOMEhafs/sorc/hafs_gsi.fd/modulefiles
#module load gsi_wcoss2

module load PrgEnv-intel/${PrgEnv_intel_ver}
module load craype/${craype_ver}
module load intel/${intel_ver}
module load cray-mpich/${cray_mpich_ver}
module load cray-pals/${cray_pals_ver}
module load hdf5/${hdf5_ver}
module load netcdf/${netcdf_ver}
module load python/${python_ver}
#module load bacio/${bacio_ver}
module load crtm/${crtm_ver}
#module load bufr/${bufr_ver}
#module load ip/${ip_ver}
#module load sp/${sp_ver}
#module load w3emc/${w3emc_ver}
#module load nemsio/${nemsio_ver}
#module load sigio/${sigio_ver}
#module load sfcio/${sfcio_ver}
#module load wrf_io/${wrf_io_ver}
export HPC_OPT=/apps/ops/para/libs
MODULEPATH=$MODULEPATH:/apps/ops/para/libs/modulefiles/mpi/intel/19.1.3.304/cray-mpich/8.1.7
module load ncio/${ncio_ver}
module load ncdiag/${ncdiag_ver}
#export PATH=$PATH:/apps/ops/para/libs/intel/19.1.3.304/cray-mpich/8.1.7/ncdiag/1.0.0/bin    #### work around for ncdiag system issue caused it not found
module list

${HOMEhafs}/jobs/JHAFS_ANALYSIS

%include <tail.h>

%manual
TASK launch

PURPOSE: Creates initial directory structure and configures the
         rest of the workflow for one storm.

This job will delete and recreate the $DATA work area for one HWRF
storm.  It sets several flags to turn on and off parts of the
workflow, or disable the entire workflow if there is no storm.  All
logic is triggered by the message file sent by the SDM via
setup_hurricane.

Labels:

  stormN - storm1-storm7 label tells whether a storm is to be run.  IF
    the storm is to be run, it tells what the storm is, and who sent
    it (NHC or JTWC).

Events:

  NoStorm - set if no storm is to be run.  The rest of the workflow sees
    the event and automatically completes via ecFlow completion clauses.

  Pom - Princeton Ocean Model (POM) is requested.  This is set for the 
    North Central Pacific, North East Pacific and North Atlantic basins
    in the current system.  If this is clear upon completion of the launch
    job, the rest of the workflow will automatically skip ocean and
    wave coupling.  

  Wave - Wavewatch 3 (WW3) coupling is requested.  This should be set
    whenever Pom is set, and enables wave coupling and related
    initialization and post-processing jobs.  If it is clear upon
    completion of the launch job, then the relevant jobs will be set
    to completed via ecFlow completion clauses.

  Gsi - Gridpoint Statistical Interpolation (GSI) data assimilation is
    enabled.  This enables the "fgat," "gsi," and "ensda" families of
    jobs, as well as the bufrprep and gsi_post jobs.  If GSI is
    disabled, those jobs are skipped via ecFlow completion clauses.

  Ensda - Ensemble Data Assimilation (ENSDA) is requested for this
    storm.  This flag should only be set if Gsi is also set.  If it is
    set, the "ensda" family of jobs is run, otherwise they are skipped
    via ecFlow completion clauses.

TROUBLESHOOTING

This job will rarely fail since it has little to do; it just sets up
some directories and makes configuration files.  If this job fails, it
is likely due to a hardware or other system issue, with one exception...

PROBLEM: Why is there no storm?

The launcher does whatever the NOAA SDM tells it to do.  The NOAA SDM
uses a script called setup_hurricane to create message files read by
the launcher job's JHWRF_LAUNCH script.  If the launcher job decided
not to run a storm, then that means the SDM told it not to.  If there
should have been a storm, then it likely means there was a
communication problem, preventing data from getting from NHC or JTWC
to the NOAA SDM.  

For NHC/CPHC storms, the NOAA SDM has a direct line to the on-call
NHC/CPHC person, who can confirm the absence of a storm.  It may then
be possible to manually edit the message and nstorms files to add the
storm in.  Alternatively, you could rerun setup_hurricane, but that
may change storm priorities.  In that case, you must rerun the entire
HWRF cycle (all storm slots).  All of this is technical possibility;
there may be procedural reasons why this cannot be done.

For JTWC storms, the NOAA SDM has the direct line to the JTWC duty
officer, but there isn't much that can be done.  JTWC lacks any way to
send vitals after the T+3 deadline.  Hence, a JTWC storm that is
missed, is missed.

%end
